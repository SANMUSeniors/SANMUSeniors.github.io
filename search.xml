<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[学习笔记TF050:TensorFlow源代码解析]]></title>
    <url>%2F2018%2F07%2F03%2Ftensorflow%E6%BA%90%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[TensorFlow目录结构。1234567891011121314151617ACKNOWLEDGMENTS #TensorFlow版本声明ADOPTERS.md #使用TensorFlow的人员或组织列表AUTHORS #TensorFlow作者的官方列表BUILDCONTRIBUTING.md #TensorFlow贡献指导ISSUE_TEMPLATE.md #提ISSUE的模板LICENSE #版权许可README.mdRELEASE.md #每次发版的change logWORKSPACE #配置移动端开发环境bower.BUILDconfiguremodels.BUILDtensorflow #主目录third_party #第三方库，包括eigen3(特征运算，SVD、LU分解等)、gpus(支持cuda)、hadoop、jpeg、llvm、py、sycltools #构建cuda支持util 123456789101112131415161718192021BUILD__init__.pyccc #采用C++进行训练的亲样例compilercontrib #将常用功能封装在一起高级APIcore #C++实现主要目录examples #各种示例g3doc #针对C++、Python版本代码文档gojavaopensource_only #声明目录python #Python实现主要目录stream_executor #流处理tensorboard #App、Web支持，以及脚本支持tensorflow.bzltf_exported_symbols.ldstf_version_script.ldstools #工具杂项user_opsworkspace.bzl contirb目录。保存常用功能封装高级API。不是官方支持。高级API完善后被官方迁移到核心TensorFlow目录或去掉。部分包(package)在https://github.com/tensorflow/models 有更完整实现。framework:很多函数在这里定义(get_varibles、get_global_step)，一些废弃或不推荐(deprecated)函数。layers:initializers.py，变量初始化函数。layers.py，层操作和权重偏置变量函数。optimizers.py，损失函数和global_step张量优化器操作。regularizers.py，带权重正则化函数。summaries.py，摘要操作添加到tf.GraphKeys.SUMMARIES集合中的函数。learn:使用TensorFlow进行深度学习高级API，训练模型、评估模型、读取批处理数据、队列功能API封装。rnn:额外RNN Cell，对RNN隐藏层改进，LSTMBlockCell、GRUBlockCell、FusedRNNCell、GridLSTMCell、AttentionCellWrapper。seq2seq:建立神经网络seq2seq层和损失函数操作。slim:TensorFlow-Slim(TF-Slim)，定义、训练、评估TensorFlow复杂模型轻量级库。TF-Slim与TensorFlow原生函数和tf.contrib其他包自由组合。TF-Slim已逐渐迁移到TensorFlow开源Models，里面有广泛使用卷积神经网络图像分类模型代友，可以从头训练模型或预测训练模型开始微调。 core目录。C语言文件，TensorFlow原始实现。 123456789101112131415BUILDcommon_runtime #公共运行库debugditributed_runtime #分布式执行模块，含有grpc session、grpc worker、grpc masterexampleframework #基础功能模块graphkernels #核心操作在CPU、CUDA内核实现lib #公共基础库opsplatform #操作系统实现相关文件protobuf #.proto文件，用于传输时结构序列化public #API头文件目录user_opsutil Protocol Buffers，谷歌公司创建的数据序列化(serialization)工具，结构化数据序列化，数据存储或RPC数据交换格式。定义协议缓冲区，生成.pb.h和.pb.cc文件。定义get、set、序列化、反序列化函数。TensorFlow核心proto文件graph_def.proto、node_def.proto、op_def.proto保存在framework目录。构图时先构建graph_def，存储下来，在实际计算时再转成图、节点、操作内存对象。tensorflow-1.1.0/tensorflow/core/framework/node_def.proto，定义proto文件。node_def.proto定义指定设备(device)操作(op)、操作属性(attr)。framework 目录还有node_def_builder.h、node_def_builder.cc、node_def_util.h、node_def_util_test.cc。在C++里操作node_def.proto的protobuf结构。 examples目录，深度学习例子，MNIST、Word2vec、Deepdream、Iris、HDF5。TensorFlow在Android系统上的移动端实现。扩展.ipynb文档教程，jupyter打开。 g3doc。存放Markdown维护的TensorFlow文档，离线手册。g3doc/api_docs目录内容从代码注释生成，不应该直接编辑。脚本tools/docs/gen_docs.sh生成API文档。无参数调用，只重新生成Python API文档，操作文档，包括Python、C++定义。传递-a，运行脚本重新生成C++ API文档，需要完装doxygen。必须从tools/docs目录调用。 python目录。激活函数、卷积函数、池化函数、损失函数、优化方法。 tensorboad目录。实现TensorFlow图表可视化工具代码，代码基于Tornado实现网页端可视化。http://www.tornadoweb.org/en/stable/ 。 TensorFlow源代码学习方法。1)了解自己研究的基本领域，图像分类、物体检测、语音识别，了解领域所用技术，卷积神经网络(convolutional neural network,CNN)、循环神经网络(recurrent neural network,RNN)，知道实现基本原理。2)运行GitHub对应基本模型，目录结构。 123456789101112131415161718192021222324AUTHORSCONTRIBTING.mdLICENSEREADME.mdWORKSPACEautoencodercompressiondifferential_privacyim2txtinceptionlm_1bnamignizerneural_gpuneural_programmernext_frame_prdictionresnetslimstreetswivelsyntaxnettextsumtransformertutorialsvideo_prediction 计算机视觉，compression(图像压缩)、im2txt(图像描述)、inception(对ImageNet数据集用Inception V3架构训练评估)、resnet(残差网络)、slim(图像分类)、street(路标识别或验证码识别)。自然语言处理，lm_1b(语言模型)、namignizer(起名字)、swivel(Swivel算法转换词向量)、syntaxnet(分词和语法分析)、textsum(文本摘要)、tutorials目录word2vec(词转换向量)。教科书式代码，看懂学懂有助今后自己实现模型。运行模型，调试、调参。完整读完MNIST或CIFAR10整个项目逻辑，就掌握TensorFlow项目架构。slim目录。TF-Slim图像分类库。定义、训练、评估复杂模型轻量级高级API。训练、评估lenet、alexnet、vgg、inception_v1、inception_v2、inception_v3、inception_v4、resnet_v1、resnet_v2，模型位于slim/nets: ####TF-Slim包含脚本从头训练模型或从预先训练网络开始训练模型并微调，slim/scripts: 1234finetune_inception_v1_on_flowers.shfinetune_inception_v3_on_flowers.shtrain_cifarnet_on_cifar10.shtrain_lenet_on_mnist.sh ####TF-Slim包含下载标准图像数集，转换TensorFlow支持TFRecords格式脚本，slim/datasets: 123456789cifar10.pydataset_factory.pydataset_utils.pydownload_and_convert_cifar10.pydownload_and_convert_flowers.pydownload_and_convert_mnist.pyflowers.pyimagenet.pymnist.py 3)结合要做的项目，找到相关论文，自己用TensorFlow实现论文内容。质的飞跃。 ##思维导图 参考资料：《TensorFlow技术解析与实战》]]></content>
      <tags>
        <tag>深度学习/tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F10%2FGAN%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%85%A5%E9%97%A8%E5%88%B0%E5%88%B6%E4%BD%9C%E7%94%9F%E6%88%90Demo%EF%BC%8C%E6%80%BB%E5%85%B1%E5%88%86%E5%87%A0%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[#GAN学习指南：从原理入门到制作生成Demo，总共分几步？本文作者：何之源 2017-01-22 10:10导语：本文介绍下GAN和DCGAN的原理，以及如何使用Tensorflow做一个简单的生成图片的demo。雷锋网注：本文作者何之源，复旦大学计算机科学硕士在读，研究人工智能计算机视觉方向。本文由雷锋网(公众号：雷锋网)编辑整理自作者知乎专栏，获授权发布。 生成式对抗网络（GAN）是近年来大热的深度学习模型。最近正好有空看了这方面的一些论文，跑了一个GAN的代码，于是写了这篇文章来介绍一下GAN。 本文主要分为三个部分： 介绍原始的GAN的原理 同样非常重要的DCGAN的原理 如何在Tensorflow跑DCGAN的代码，生成如题图所示的动漫头像，附送数据集哦 :-) 一、GAN原理介绍 说到GAN第一篇要看的paper当然是Ian Goodfellow大牛的Generative Adversarial Networks，这篇paper算是这个领域的开山之作。 GAN的基本原理其实非常简单，这里以生成图片为例进行说明。假设我们有两个网络，G（Generator）和D（Discriminator）。正如它的名字所暗示的那样，它们的功能分别是： G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记做G(z)。 D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D（x）代表x为真实图片的概率，如果为1，就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片。 在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。 最后博弈的结果是什么？在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。 这样我们的目的就达成了：我们得到了一个生成式的模型G，它可以用来生成图片。 以上只是大致说了一下GAN的核心原理，如何用数学语言描述呢？这里直接摘录论文里的公式： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 简单分析一下这个公式： 整个式子由两项构成。x表示真实图片，z表示输入G网络的噪声，而G(z)表示G网络生成的图片。 D(x)表示D网络判断真实图片是否真实的概率（因为x就是真实的，所以对于D来说，这个值越接近1越好）。而D(G(z))是D网络判断G生成的图片的是否真实的概率。 G的目的：上面提到过，D(G(z))是D网络判断G生成的图片是否真实的概率，G应该希望自己生成的图片“越接近真实越好”。也就是说，G希望D(G(z))尽可能得大，这时V(D, G)会变小。因此我们看到式子的最前面的记号是min_G。 D的目的：D的能力越强，D(x)应该越大，D(G(x))应该越小。这时V(D,G)会变大。因此式子对于D来说是求最大(max_D) 下面这幅图片很好地描述了这个过程： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 那么如何用随机梯度下降法训练D和G？论文中也给出了算法： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 这里红框圈出的部分是我们要额外注意的。第一步我们训练D，D是希望V(G, D)越大越好，所以是加上梯度(ascending)。第二步训练G时，V(G, D)越小越好，所以是减去梯度(descending)。整个训练过程交替进行。 二、DCGAN原理介绍 我们知道深度学习中对图像处理应用最好的模型是CNN，那么如何把CNN与GAN结合？DCGAN是这方面最好的尝试之一（点击查看论文） DCGAN的原理和GAN是一样的，这里就不在赘述。它只是把上述的G和D换成了两个卷积神经网络（CNN）。但不是直接换就可以了，DCGAN对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度，这些改变有： 取消所有pooling层。G网络中使用转置卷积（transposed convolutional layer）进行上采样，D网络中用加入stride的卷积代替pooling。 在D和G中均使用batch normalization 去掉FC层，使网络变为全卷积网络 G网络中使用ReLU作为激活函数，最后一层使用tanh D网络中使用LeakyReLU作为激活函数 DCGAN中的G网络示意：GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 三、DCGAN in Tensorflow 好了，上面说了一通原理，下面说点有意思的实践部分的内容。 DCGAN的原作者用DCGAN生成LSUN的卧室图片，这并不是特别有意思。之前在网上看到一篇文章 Chainerで顔イラストの自動生成 - Qiita ，是用DCGAN生成动漫人物头像的，效果如下： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 这是个很有趣的实践内容。可惜原文是用Chainer做的，这个框架使用的人不多。下面我们就在Tensorflow中复现这个结果。 原始数据集的搜集 首先我们需要用爬虫爬取大量的动漫图片，原文是在这个网站：http://safebooru.donmai.us/中爬取的。我尝试的时候，发现在我的网络环境下无法访问这个网站，于是我就写了一个简单的爬虫爬了另外一个著名的动漫图库网站：konachan.net。 爬虫代码如下： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 这个爬虫大概跑了一天，爬下来12万张图片，大概是这样的： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 可以看到这里面的图片大多数比较杂乱，还不能直接作为数据训练，我们需要用合适的工具，截取人物的头像进行训练。 头像截取 截取头像和原文一样，直接使用github上一个基于opencv的工具：nagadomi。 简单包装下代码： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 截取头像后的人物数据： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 这样就可以用来训练了！ 如果你不想从头开始爬图片，可以直接使用我爬好的头像数据（275M，约5万多张图片）：百度云盘 提取码：g5qa 训练 DCGAN在Tensorflow中已经有人造好了轮子：carpedm20/DCGAN，我们直接使用这个代码就可以了。 不过原始代码中只提供了有限的几个数据库，如何训练自己的数据？在model.py中我们找到读数据的几行代码： if config.dataset == ‘mnist’: data_X, data_y = self.load_mnist() else: data = glob(os.path.join(“./data”, config.dataset, “*.jpg”)) 这样读数据的逻辑就很清楚了，我们在data文件夹中再新建一个anime文件夹，把图片直接放到这个文件夹里，运行时指定–dataset anime即可。 运行指令（参数含义：指定生成的图片的尺寸为48x48，我们图片的大小是96x96，跑300个epoch）： python main.py –image_size 96 –output_size 48 –dataset anime –is_crop True –is_train True –epoch 300 结果 第1个epoch跑完（只有一点点轮廓）： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 第5个epoch之后的结果：GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 第10个epoch： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 200个epoch，仔细看有些图片确实是足以以假乱真的： GAN学习指南：从原理入门到制作生成Demo，总共分几步？ 题图是我从第300个epoch生成的。 四、总结和后续 简单介绍了一下GAN和DCGAN的原理。以及如何使用Tensorflow做一个简单的生成图片的demo。 一些后续阅读： Ian Goodfellow对GAN一系列工作总结的ppt，确实精彩，推荐：GAN之父NIPS 2016演讲现场直击：全方位解读生成对抗网络的原理及未来 GAN论文汇总，包含code：zhangqianhui/AdversarialNetsPapers 雷锋网特约稿件，未经授权禁止转载。详情见转载须知。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F08%2F%E7%AE%80%E5%8D%95%E6%98%93%E5%AD%A6%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94%E6%9E%81%E9%99%90%E5%AD%A6%E4%B9%A0%E6%9C%BA(ELM)%20(1)%2F</url>
    <content type="text"><![CDATA[title: 简单易学的机器学习算法——极限学习机(ELM)tags: 机器学习 算法categories: 原理 一、极限学习机的概念 极限学习机(Extreme Learning Machine) ELM，是由黄广斌提出来的求解单隐层神经网络的算法。 ELM最大的特点是对于传统的神经网络，尤其是单隐层前馈神经网络(SLFNs)，在保证学习精度的前提下比传统的学习算法速度更快。 二、极限学习机的原理ELM是一种新型的快速学习算法，对于单隐层神经网络，ELM可以随机初始化输入权重和偏置并得到相应的输出权重。 (选自黄广斌老师的PPT) 对于一个单隐层神经网络(见Figure 1)，假设有个任意的样本，其中，。对于一个有个隐层节点的单隐层神经网络可以表示为 其中，为激活函数，为输入权重，为输出权重，是第个隐层单元的偏置。表示和的内积。 单隐层神经网络学习的目标是使得输出的误差最小，可以表示为 即存在，和，使得 可以矩阵表示为 其中，是隐层节点的输出，为输出权重，为期望输出。 ， 为了能够训练单隐层神经网络，我们希望得到，和，使得 其中，，这等价于最小化损失函数 传统的一些基于梯度下降法的算法，可以用来求解这样的问题，但是基本的基于梯度的学习算法需要在迭代的过程中调整所有参数。而在ELM算法中, 一旦输入权重和隐层的偏置被随机确定，隐层的输出矩阵就被唯一确定。训练单隐层神经网络可以转化为求解一个线性系统。并且输出权重可以被确定 其中，是矩阵的Moore-Penrose广义逆。且可证明求得的解的范数是最小的并且唯一。 三、实验 我们使用《简单易学的机器学习算法——Logistic回归》中的实验数据。 原始数据集我们采用统计错误率的方式来评价实验的效果，其中错误率公式为： 对于这样一个简单的问题，。MATLAB代码主程序[plain] view plain copy%% 主函数，二分类问题 %导入数据集A = load(‘testSet.txt’); data = A(:,1:2);%特征label = A(:,3);%标签 [N,n] = size(data); L = 100;%隐层节点个数m = 2;%要分的类别数 %–初始化权重和偏置矩阵W = rand(n,L)2-1;b_1 = rand(1,L);ind = ones(N,1);b = b_1(ind,:);%扩充成NL的矩阵 tempH = data*W+b;H = g(tempH);%得到H %对输出做处理temp_T=zeros(N,m);for i = 1:N if label(i,:) == 0 temp_T(i,1) = 1; else temp_T(i,2) = 1; endendT = temp_T*2-1; outputWeight = pinv(H)*T; %–画出图形x_1 = data(:,1);x_2 = data(:,2);hold onfor i = 1 : N if label(i,:) == 0 plot(x_1(i,:),x_2(i,:),’.g’); else plot(x_1(i,:),x_2(i,:),’.r’); endend output = H * outputWeight;%—计算错误率tempCorrect=0;for i = 1:N [maxNum,index] = max(output(i,:)); index = index-1; if index == label(i,:); tempCorrect = tempCorrect+1; endend errorRate = 1-tempCorrect./N; 激活函数[plain] view plain copyfunction [ H ] = g( X ) H = 1 ./ (1 + exp(-X));end]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F06%2F06%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[我的选择,我的路]]></title>
    <url>%2F2018%2F06%2F06%2F%E6%88%91%E7%9A%84%E8%A7%84%E5%88%92%E4%B8%8E%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%2F</url>
    <content type="text"><![CDATA[#我的规划与职业发展 ##这是现实需求： ###AI产业篇：国家发展战略：《规划》中提到，把高端人才队伍建设作为人工智能发展的重中之重，坚持培养和引进相结合，完善人工智能教育体系，加强人才储备和梯队建设，特别是加快引进全球顶级人才和青年人才，形成我国人工智能人才高地。同时，中国政府也加大力度建设人工智能学科。《规划》提出，要完善人工智能领域学科布局，设立人工智能专业，推动人工智能领域一级学科建设，尽快在试点院校建立人工智能学院，增加人工智能相关学科方向的博士、硕士招生名额。加强产学研合作，鼓励高校、科研院所与企业等机构合作开展人工智能学科建设。人才分布：中国AI产业的主要从业人员集中在应用层，而美国主要集中在基础层和技术层。中国的AI基础层人才储备薄弱，尤其是处理器/芯片和AI技术平台上，中国缺乏驱动能源，即缺乏高级人才支持和高端教育体系为产业发展续航自然语言处理，美国从业者人数是中国的3倍，美国20200人，中国6600人；处理器/芯片，美国从业者人数是中国的13.8倍，美国17900人，中国1300人；机器学习应用，美国从业者人数是中国的1.8倍，美国17600人，中国9800人；智能无人机，美国从业者人数是中国的1.98倍，美国9220人，中国4660人；计算机视觉，美国从业者人数是中国的2.9倍，美国4335人，中国1510人。中国仅在智能机器人领域从业者稍多，6400人，约为美国同领域人数的3倍。在基础层上，美国AI从业者人数17900人，占美国从业者总人数的22%，中国在该领域从业者人数1300人，仅为中国团队人数的3.3%。从人数来看，美国基础层从业者数量是中国的13.98倍，占比是中国的6.7倍。在技术层上，美国从业者29400人，占据全美37.3%，中国12000人，占据全国33%，美国从业者数量是中国的2.26倍，但两国占比相差不大。在应用层上，美国从业者31400人，占比全美39.89%，中国24300人，占比61.8%，美国人数是中国的1.29倍，但占比小于中国21.91个百分点。从数据上反映，计算机视觉的确存在缺口空缺，机器学习竞争较大。学者人数最多的领域是机器学习，其次是计算机视觉、机器人和自然语言处理。 中国AI人才供求研究部分的数据均抽样自BOSS直聘招聘和求职者大数据体系，抽取与人工智能直接相关的职位数据，如自动驾驶、自然语言处理、计算机视觉、搜索算法、算法工程师、推荐算法、图形开发、深度学习、图像识别、语音识别、机器视觉、语义识别、声纹识别、等。数据组依据填写信息的完整度和信息可信度，对抽取样本数据进行了清洗，剔除了信息填写虚假，不符合要的数据。上述状况基本可信：同样需要后台 ####各类职位所需技能自动驾驶的技术栈要求较远- #####1.自动驾驶工程师-这个方向暂时排除。 #####2.自然语言处理：-这个得查看入门难度。 #####3计算机视觉-多处有重合。–可以考虑吧。看机遇 ####搜索算法工程师小结选定后就要专心做考虑历史进程与个人兴趣AI人工智能：这是内心喜欢的选定机器学习算法应用工程师-好处就是我目前已经对这个方向有些许了解，有入门基础。对这个方向也比较喜欢，研究生课题可能也就是这-医疗大数据，以后很有可能就是往这个方向发展。这个方向的难处就是有挑战有意思，需要扎实的数学功底与算法基础功底。有意思。可能存在泡沫风险。这个要求深度，可替代性比较小。未来及长期发展较好。后台开发：要求广度，学得比较杂，容易被替代，后期可能转管理。目前也差不多饱和了。？那研究生就以课题兼顾，侧重机器学习，兼顾点java开发。Ok。Ok，暂定这个。看了几个职位这两个并不是完全不重合的。所以无所谓太大纠结！]]></content>
      <categories>
        <category>选择</category>
      </categories>
      <tags>
        <tag>目标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的选择，我的路]]></title>
    <url>%2F2018%2F06%2F06%2F%E6%88%91%E7%9A%84%E9%80%89%E6%8B%A9%EF%BC%8C%EF%BC%8C%E6%88%91%E7%9A%84%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[#我的规划与职业发展 ##这是现实需求： ###AI产业篇：国家发展战略：《规划》中提到，把高端人才队伍建设作为人工智能发展的重中之重，坚持培养和引进相结合，完善人工智能教育体系，加强人才储备和梯队建设，特别是加快引进全球顶级人才和青年人才，形成我国人工智能人才高地。同时，中国政府也加大力度建设人工智能学科。《规划》提出，要完善人工智能领域学科布局，设立人工智能专业，推动人工智能领域一级学科建设，尽快在试点院校建立人工智能学院，增加人工智能相关学科方向的博士、硕士招生名额。加强产学研合作，鼓励高校、科研院所与企业等机构合作开展人工智能学科建设。人才分布： 中国AI产业的主要从业人员集中在应用层，而美国主要集中在基础层和技术层。中国的AI基础层人才储备薄弱，尤其是处理器/芯片和AI技术平台上，中国缺乏驱动能源，即缺乏高级人才支持和高端教育体系为产业发展续航自然语言处理，美国从业者人数是中国的3倍，美国20200人，中国6600人；处理器/芯片，美国从业者人数是中国的13.8倍，美国17900人，中国1300人；机器学习应用，美国从业者人数是中国的1.8倍，美国17600人，中国9800人；智能无人机，美国从业者人数是中国的1.98倍，美国9220人，中国4660人；计算机视觉，美国从业者人数是中国的2.9倍，美国4335人，中国1510人。中国仅在智能机器人领域从业者稍多，6400人，约为美国同领域人数的3倍。在基础层上，美国AI从业者人数17900人，占美国从业者总人数的22%，中国在该领域从业者人数1300人，仅为中国团队人数的3.3%。从人数来看，美国基础层从业者数量是中国的13.98倍，占比是中国的6.7倍。在技术层上，美国从业者29400人，占据全美37.3%，中国12000人，占据全国33%，美国从业者数量是中国的2.26倍，但两国占比相差不大。在应用层上，美国从业者31400人，占比全美39.89%，中国24300人，占比61.8%，美国人数是中国的1.29倍，但占比小于中国21.91个百分点。从数据上反映，计算机视觉的确存在缺口空缺，机器学习竞争较大。学者人数最多的领域是机器学习，其次是计算机视觉、机器人和自然语言处理。 中国AI人才供求研究部分的数据均抽样自BOSS直聘招聘和求职者大数据体系，抽取与人工智能直接相关的职位数据，如自动驾驶、自然语言处理、计算机视觉、搜索算法、算法工程师、推荐算法、图形开发、深度学习、图像识别、语音识别、机器视觉、语义识别、声纹识别、等。数据组依据填写信息的完整度和信息可信度，对抽取样本数据进行了清洗，剔除了信息填写虚假，不符合要的数据。上述状况基本可信：同样需要后台 ####各类职位所需技能自动驾驶的技术栈要求较远- #####1.自动驾驶工程师-这个方向暂时排除。 #####2.自然语言处理：-这个得查看入门难度。 #####3计算机视觉-多处有重合。–可以考虑吧。看机遇 ####搜索算法工程师小结选定后就要专心做考虑历史进程与个人兴趣AI人工智能：这是内心喜欢的选定机器学习算法应用工程师-好处就是我目前已经对这个方向有些许了解，有入门基础。对这个方向也比较喜欢，研究生课题可能也就是这-医疗大数据，以后很有可能就是往这个方向发展。这个方向的难处就是有挑战有意思，需要扎实的数学功底与算法基础功底。有意思。可能存在泡沫风险。这个要求深度，可替代性比较小。未来及长期发展较好。后台开发：要求广度，学得比较杂，容易被替代，后期可能转管理。目前也差不多饱和了。？那研究生就以课题兼顾，侧重机器学习，兼顾点java开发。Ok。Ok，暂定这个。看了几个职位这两个并不是完全不重合的。所以无所谓太大纠结！]]></content>
      <tags>
        <tag>感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github+hexo文章搭建]]></title>
    <url>%2F2018%2F06%2F05%2Fgithub-hexo%E6%96%87%E7%AB%A0%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
</search>
